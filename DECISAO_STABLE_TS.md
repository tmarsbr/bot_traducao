# ğŸ¯ DecisÃ£o: Faster-Whisper vs Stable-TS

## ğŸ’¡ Resumo Executivo (TL;DR)

**Para o seu caso (bot de traduÃ§Ã£o de vÃ­deos):**

```
VÃ­deos < 30 min  â†’  Faster-Whisper (V3 otimizada)  âš¡
VÃ­deos > 45 min  â†’  Stable-TS                      ğŸ¯
ProduÃ§Ã£o final   â†’  Stable-TS (se tempo permitir) âœ¨
```

---

## ğŸ”„ EstratÃ©gia HÃ­brida Recomendada

### ConfiguraÃ§Ã£o Ideal

```python
# PseudocÃ³digo para adicionar ao pipeline

if duracao_video < 30_minutos:
    usar_faster_whisper_v3()  # RÃ¡pido e bom
elif duracao_video < 60_minutos:
    if tem_tempo:
        usar_stable_ts()  # Melhor qualidade
    else:
        usar_faster_whisper_v3()  # AceitÃ¡vel
else:  # > 1 hora
    usar_stable_ts()  # OBRIGATÃ“RIO (evita time drift)
```

---

## ğŸ“Š AnÃ¡lise de ROI (Retorno do Investimento de Tempo)

### Exemplo: VÃ­deo de 50 minutos

| SoluÃ§Ã£o | Tempo | Qualidade | Reprocessar? |
|---------|-------|-----------|--------------|
| **Faster-Whisper V3** | 6 min | 85% boa | Talvez (+10 min) |
| **Stable-TS** | 18 min | 98% boa | Raramente |

**ConclusÃ£o:** Em vÃ­deos longos, Stable-TS economiza tempo total (evita retrabalho).

---

## ğŸ¬ Respostas Ã s Suas Perguntas

### "Quer que eu explique como configurar o ficheiro .ASS gerado para ter aquele visual de 'fundo translÃºcido preto' igual ao da Netflix?"

**Resposta:** Isso jÃ¡ estÃ¡ implementado! ğŸ‰

No `embutir_legendas.py` (que vocÃª usa), o ASS jÃ¡ tem:
```
BackColour=&H80000000  # Preto com 50% de transparÃªncia
BorderStyle=3          # Caixa ao redor do texto
FontSize=58            # Fonte grande (+81%)
```

Se quiser ajustar a transparÃªncia:
```
&H80000000  â†’  80 = transparÃªncia (00 = opaco, FF = transparente)
```

### "ou preferes focar primeiro em testar se a sincronia ficou perfeita?"

**SugestÃ£o:** Teste PRIMEIRO com 1 vÃ­deo problemÃ¡tico.

**Comando:**
```bash
pip install stable-ts
python transcritor_stable_ts.py "video_que_desincronizou.mp4"
```

Compare os 2 SRTs:
- `video_EN.srt` (Faster-Whisper)
- `video_STABLE.srt` (Stable-TS)

Abra ambos no VLC e veja qual sincroniza melhor no final do vÃ­deo.

---

## ğŸ› ï¸ ImplementaÃ§Ã£o PrÃ¡tica: Adicionar ao Pipeline

### OpÃ§Ã£o A: Script Separado (Mais Simples)

**Uso:** Rodar apenas quando Faster-Whisper falhar

```bash
# Pipeline normal
python extrair_proximos_srt_v3_otimizado.py

# Se algum vÃ­deo descincronizar, reprocessar com:
python transcritor_stable_ts.py "video_problema.mp4"
```

âœ… **Vantagens:** 
- NÃ£o quebra o pipeline existente
- Usa Stable-TS apenas quando necessÃ¡rio

### OpÃ§Ã£o B: IntegraÃ§Ã£o AutomÃ¡tica (Mais Robusto)

Modificar `extrair_proximos_srt_v3_otimizado.py` para detectar duraÃ§Ã£o:

```python
# No inÃ­cio do arquivo
try:
    from transcritor_stable_ts import transcrever_video_longo
    STABLE_TS_DISPONIVEL = True
except:
    STABLE_TS_DISPONIVEL = False

# Na funÃ§Ã£o extrair_srt_otimizado
duracao = obter_duracao_video(video_path)

if duracao > 2700 and STABLE_TS_DISPONIVEL:  # 45 min
    print("  ğŸ¯ VÃ­deo longo detectado: usando Stable-TS...")
    srt_path = transcrever_video_longo(video_path)
else:
    # LÃ³gica atual (Faster-Whisper)
    ...
```

---

## ğŸ“¦ InstalaÃ§Ã£o do Stable-TS

### Passo a Passo

```bash
# 1. Instalar
pip install stable-ts

# 2. Testar
python transcritor_stable_ts.py

# 3. Se der erro de CUDA (normal sem GPU NVIDIA)
# Edite o script e force CPU:
usar_gpu=False
```

**Tamanho do download:** ~4GB (PyTorch + modelos)

**Tempo da primeira execuÃ§Ã£o:** ~10min (baixa modelos)

---

## ğŸ¯ RecomendaÃ§Ã£o Final

### Para o seu projeto:

1. **Curto prazo (agora):**
   - Continue usando `extrair_proximos_srt_v3_otimizado.py`
   - Instale Stable-TS como "plano B"
   - Teste em 1-2 vÃ­deos longos para validar

2. **MÃ©dio prazo (prÃ³xima semana):**
   - Se Stable-TS funcionar bem, implemente **OpÃ§Ã£o A** (script separado)
   - Use para vÃ­deos > 50 minutos

3. **Longo prazo (depois):**
   - Se processar muitos vÃ­deos longos, implemente **OpÃ§Ã£o B** (automÃ¡tico)

---

## ğŸ› Problemas Conhecidos e SoluÃ§Ãµes

### 1. "ModuleNotFoundError: No module named 'stable_whisper'"

```bash
pip install stable-ts
```

### 2. "CUDA out of memory" (GPU cheia)

Edite `transcritor_stable_ts.py`:
```python
usar_gpu=False  # Linha ~200
```

### 3. "FFmpeg not found"

Certifique-se que FFmpeg estÃ¡ no PATH:
```bash
ffmpeg -version
```

### 4. Muito lento mesmo em GPU

Normal. Stable-TS Ã© 2-3x mais lento que Faster-Whisper.

**Alternativas:**
- Use modelo `medium` em vez de `large-v3`
- Processe durante a noite
- Use apenas para vÃ­deos crÃ­ticos

---

## âœ… Checklist de DecisÃ£o

VocÃª PRECISA de Stable-TS se:

- [ ] Tem vÃ­deos > 1 hora
- [ ] Legendas desincronizam no final do vÃ­deo
- [ ] Muitas legendas falsas em momentos de mÃºsica
- [ ] PrecisÃ£o Ã© crÃ­tica (cliente, produÃ§Ã£o)

Pode continuar com Faster-Whisper V3 se:

- [x] Maioria dos vÃ­deos < 30 min
- [x] Velocidade Ã© prioridade
- [x] Qualidade atual Ã© aceitÃ¡vel
- [x] Processamento em lote grande

---

## ğŸ“ PrÃ³ximos Passos Sugeridos

**Pergunta para vocÃª:**

Quer que eu:

**A)** Crie uma versÃ£o hÃ­brida automÃ¡tica do `extrair_proximos_srt_v3_otimizado.py` que detecta vÃ­deos longos e usa Stable-TS?

**B)** Explique como configurar estilos ASS personalizados (cores, posiÃ§Ãµes, karaoke)?

**C)** Foque em otimizar ainda mais o Faster-Whisper V3 para vÃ­deos mÃ©dios (30-45min)?

**D)** Deixe como estÃ¡ e vocÃª testa o Stable-TS manualmente quando precisar?

---

**Minha recomendaÃ§Ã£o:** OpÃ§Ã£o **D** primeiro (testar), depois **A** se gostar dos resultados. ğŸš€
